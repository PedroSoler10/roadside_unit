<launch>

	<!-- VIDEO SOURCE -->
	<!-- <arg name="input" default="csi://0"/> -->
	<arg name="input" default="/dev/video1"/>
	<arg name="input_width" default="0"/>
	<arg name="input_height" default="0"/>
	<arg name="input_codec" default="unknown"/>
	<arg name="input_loop" default="0"/>

	<include file="$(find ros_deep_learning)/launch/video_source.ros1.launch">
		<arg name="input" value="$(arg input)"/>
		<arg name="input_width" value="$(arg input_width)"/>
		<arg name="input_height" value="$(arg input_height)"/>
		<arg name="input_codec" value="$(arg input_codec)"/>
		<arg name="input_loop" value="$(arg input_loop)"/>
	</include>

	<!-- DETECTNET -->
	<arg name="model_name" default="ssd-mobilenet-v2"/>
	<arg name="model_path" default=""/>
	<arg name="prototxt_path" default=""/>
	<arg name="class_labels_path" default=""/>
	<arg name="input_blob" default=""/>
	<arg name="output_cvg" default=""/>
	<arg name="output_bbox" default=""/>
	<arg name="overlay_flags" default="box,labels,conf"/>
	<arg name="mean_pixel_value" default="0.0"/>
	<arg name="threshold" default="0.5"/>

	<node pkg="ros_deep_learning" type="detectnet" name="detectnet" output="screen">
		<remap from="/detectnet/image_in" to="/video_source/raw"/>
		<param name="model_name" value="$(arg model_name)"/>
		<param name="model_path" value="$(arg model_path)"/>
		<param name="prototxt_path" value="$(arg prototxt_path)"/>
		<param name="class_labels_path" value="$(arg class_labels_path)"/>
		<param name="input_blob" value="$(arg input_blob)"/>
		<param name="output_cvg" value="$(arg output_cvg)"/>
		<param name="output_bbox" value="$(arg output_bbox)"/>
		<param name="overlay_flags" value="$(arg overlay_flags)"/>
		<param name="mean_pixel_value" value="$(arg mean_pixel_value)"/>
		<param name="threshold" value="$(arg threshold)"/>
	</node>

	<!-- SCENARIO CLASSIFICATOR -->
    <node name="scenario_classificator" pkg="perception_pkg" type="scenario_classificator.py" />

	<!-- SCENARIO VISUALIZER -->
    <node name="scenario_visualizer" pkg="debugging_pkg" type="scenario_visualizer.py" />

	<!-- VIDEO OUTPUT -->
	<arg name="image_nvidia" default="true" />
	<arg name="output" default="display://0"/>
	<arg name="output_codec" default="unknown"/>
	<arg name="output_bitrate" default="0"/>
    <arg name="image_nvidia_topic" default="/scenario/overlay" />

	<include file="$(find ros_deep_learning)/launch/video_output.ros1.launch" if="$(arg image_nvidia)">
		<arg name="topic" value="$(arg image_nvidia_topic)"/>
		<arg name="output" value="$(arg output)"/>
		<arg name="output_codec" value="$(arg output_codec)"/>
		<arg name="output_bitrate" value="$(arg output_bitrate)"/>
	</include>


    <!-- IMAGE VIEWER -->
    <arg name="image_view" default="false" />
    <arg name="image_view_topic" default="/scenario/overlay" />
    
    <node name="image_view" pkg="image_view" type="image_view" respawn="false" output="screen" if="$(arg image_view)">
        <remap from="image" to="$(arg image_view_topic)"/>
        <param name="autosize" value="true" />
    </node>
</launch>
